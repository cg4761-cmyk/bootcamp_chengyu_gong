{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Starter â€” Stage 14: Deployment & Monitoring\n",
    "\n",
    "Use this template to draft your reflection and (optionally) sketch a dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "**Risks if deployed:**  \n",
    "If deployed, the model faces several credible risks. Data quality issues such as schema drift or higher null rates could cause the model to misinterpret inputs. Model risks include declining performance if distributions shift or if labels are delayed for retraining. System risks include API downtime or high latency, which would make the service unusable for end users. Business risks include incorrect predictions leading to misaligned KPIs, such as reduced approval accuracy or lower customer trust.\n",
    "\n",
    "**Monitoring metrics across layers (Data/Model/System/Business):**  \n",
    "At the data layer, I would track schema hash changes and null rate thresholds (nulls > 2% triggers alert) as well as data freshness (batch delay > 30 minutes). At the model layer, I would monitor two-week rolling AUC and set a trigger if AUC < 0.60, along with population stability index (PSI > 0.05). At the system layer, I would monitor API latency (p95 latency > 250ms) and error rates (> 1% of calls failing). At the business layer, I would monitor approval rates and revenue per decision, with a flag if approval rate drops by more than 10% compared to baseline.\n",
    "\n",
    "**Ownership & handoffs:**  \n",
    "The data engineering team owns data pipeline monitoring and schema checks. The applied ML team owns model performance dashboards and retraining triggers. System reliability is owned by platform on-call engineers who handle latency or error rate alerts. Business KPIs are reviewed weekly by product managers. Handoff occurs via documented runbooks: alerts first notify on-call, who investigates logs and either mitigates or escalates. Retraining cadence is monthly, or sooner if thresholds are breached. Rollback decisions are approved by the ML lead with notification to business stakeholders.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Optional: Dashboard Sketch\n",
    "Describe panels and key charts. You can also attach an image file in your repo (png/pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional helper: simple structure to list metrics\n",
    "monitoring = {\n",
    "    'data': ['freshness_minutes', 'null_rate', 'schema_hash'],\n",
    "    'model': ['rolling_mae_or_auc', 'calibration_error'],\n",
    "    'system': ['p95_latency_ms', 'error_rate'],\n",
    "    'business': ['approval_rate', 'bad_rate']\n",
    "}\n",
    "monitoring"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
