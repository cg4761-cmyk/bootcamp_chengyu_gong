{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cebe1f22",
   "metadata": {},
   "source": [
    "# API Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbfab0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key present: True\n"
     ]
    }
   ],
   "source": [
    "import os, json, time, datetime as dt, csv, pathlib\n",
    "from typing import Dict, List\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ALPHA_KEY = os.getenv(\"ALPHAVANTAGE_API_KEY\")\n",
    "print(\"API Key present:\", ALPHA_KEY is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1365dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Alpha Vantage: True\n",
      "[WARN] Alpha Vantage failed: Unexpected response keys: ['Information']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Got data from yfinance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "SYMBOL = \"AAPL\"\n",
    "use_alpha = bool(ALPHA_KEY)\n",
    "print(\"Using Alpha Vantage:\", use_alpha)\n",
    "\n",
    "df_api = None\n",
    "\n",
    "if use_alpha:\n",
    "    try:\n",
    "        url = \"https://www.alphavantage.co/query\"\n",
    "        params = {\n",
    "            \"function\": \"TIME_SERIES_DAILY_ADJUSTED\",\n",
    "            \"symbol\": SYMBOL,\n",
    "            \"outputsize\": \"compact\",\n",
    "            \"apikey\": ALPHA_KEY,\n",
    "            \"datatype\": \"json\"\n",
    "        }\n",
    "        r = requests.get(url, params=params, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        js = r.json()\n",
    "        key = [k for k in js.keys() if \"Time Series\" in k]\n",
    "        if not key:\n",
    "            raise ValueError(f\"Unexpected response keys: {list(js.keys())}\")\n",
    "        series = js[key[0]]\n",
    "        df_api = (pd.DataFrame(series).T\n",
    "                  .rename_axis('date')\n",
    "                  .reset_index())\n",
    "        df_api = df_api[['date', '5. adjusted close']].rename(columns={'5. adjusted close': 'adj_close'})\n",
    "        df_api['date'] = pd.to_datetime(df_api['date'])\n",
    "        df_api['adj_close'] = pd.to_numeric(df_api['adj_close'])\n",
    "        print(\"[OK] Got data from Alpha Vantage\")\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] Alpha Vantage failed:\", e)\n",
    "        use_alpha = False  # fallback\n",
    "\n",
    "if not use_alpha:\n",
    "    import yfinance as yf\n",
    "    df_yf = yf.download(SYMBOL, period=\"6mo\", interval=\"1d\", auto_adjust=False)\n",
    "\n",
    "    if isinstance(df_yf.columns, pd.MultiIndex):\n",
    "        df_yf.columns = df_yf.columns.get_level_values(0)\n",
    "\n",
    "    df_yf = df_yf.reset_index()\n",
    "\n",
    "    if \"Adj Close\" in df_yf.columns:\n",
    "        df_api = df_yf[['Date', 'Adj Close']].rename(columns={'Date': 'date', 'Adj Close': 'adj_close'})\n",
    "    else:\n",
    "        df_api = df_yf[['Date', 'Close']].rename(columns={'Date': 'date', 'Close': 'adj_close'})\n",
    "\n",
    "    print(\"[OK] Got data from yfinance\")\n",
    "\n",
    "df_api = df_api.sort_values('date').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d16a3a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation passed\n"
     ]
    }
   ],
   "source": [
    "# --- Validation ---\n",
    "assert 'date' in df_api.columns and 'adj_close' in df_api.columns, \"lack requre column\"\n",
    "assert df_api['date'].notna().all(), \"date have NA\"\n",
    "assert df_api['adj_close'].notna().all(), \"adj_close have NA\"\n",
    "assert len(df_api) > 0, \"DataFrame is empty\"\n",
    "print(\"Validation passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6310134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price       date   adj_close\n",
      "0     2025-02-18  243.873062\n",
      "1     2025-02-19  244.272079\n",
      "2     2025-02-20  245.229736\n",
      "3     2025-02-21  244.950424\n",
      "4     2025-02-24  246.496643\n"
     ]
    }
   ],
   "source": [
    "print(df_api.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0522a89",
   "metadata": {},
   "source": [
    "saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3cb1e9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ..\\data\\raw\\api_yfinance_AAPL_20250818-1033.csv\n"
     ]
    }
   ],
   "source": [
    "RAW_DIR = Path(\"..\") / \"data\" / \"raw\"\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "source = \"alpha\" if use_alpha else \"yfinance\"\n",
    "fname = RAW_DIR / f\"api_{source}_{SYMBOL}_{pd.Timestamp.now().strftime('%Y%m%d-%H%M')}.csv\"\n",
    "\n",
    "df_api.to_csv(fname, index=False)\n",
    "print(\"Saved:\", fname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a23845",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca6804b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation passed (Scraping)\n",
      "Saved: ..\\data\\raw\\scrape_wikipedia_sp500_20250818-1033.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>GICSSector</th>\n",
       "      <th>GICS Sub-Industry</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Date added</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Founded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>Saint Paul, Minnesota</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>0000066740</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A. O. Smith</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Building Products</td>\n",
       "      <td>Milwaukee, Wisconsin</td>\n",
       "      <td>2017-07-26</td>\n",
       "      <td>0000091142</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>0000001800</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Biotechnology</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>0001551152</td>\n",
       "      <td>2013 (1888)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>0001467373</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol             Security              GICSSector  \\\n",
       "0    MMM                   3M             Industrials   \n",
       "1    AOS          A. O. Smith             Industrials   \n",
       "2    ABT  Abbott Laboratories             Health Care   \n",
       "3   ABBV               AbbVie             Health Care   \n",
       "4    ACN            Accenture  Information Technology   \n",
       "\n",
       "                GICS Sub-Industry    Headquarters Location  Date added  \\\n",
       "0        Industrial Conglomerates    Saint Paul, Minnesota  1957-03-04   \n",
       "1               Building Products     Milwaukee, Wisconsin  2017-07-26   \n",
       "2           Health Care Equipment  North Chicago, Illinois  1957-03-04   \n",
       "3                   Biotechnology  North Chicago, Illinois  2012-12-31   \n",
       "4  IT Consulting & Other Services          Dublin, Ireland  2011-07-06   \n",
       "\n",
       "          CIK      Founded  \n",
       "0  0000066740         1902  \n",
       "1  0000091142         1916  \n",
       "2  0000001800         1888  \n",
       "3  0001551152  2013 (1888)  \n",
       "4  0001467373         1989  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "SCRAPE_URL = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "headers = {\"User-Agent\": \"AFE-Course-Notebook/1.0 (contact: instructor@example.edu)\"}\n",
    "\n",
    "try:\n",
    "    resp = requests.get(SCRAPE_URL, headers=headers, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "    # Find Constituents table\n",
    "    table = soup.find(\"table\", {\"id\": \"constituents\"})\n",
    "    if table is None:\n",
    "        raise ValueError(\"Constituents table not found\")\n",
    "\n",
    "    rows = []\n",
    "    for tr in table.find_all(\"tr\"):\n",
    "        cells = [td.get_text(strip=True) for td in tr.find_all(['td','th'])]\n",
    "        if cells:\n",
    "            rows.append(cells)\n",
    "\n",
    "    # First row is header\n",
    "    header, *data = rows\n",
    "    df_scrape = pd.DataFrame(data, columns=header)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Scrape failed (fallback to inline demo).\", e)\n",
    "    html = \"\"\"\n",
    "    <table>\n",
    "      <tr><th>Symbol</th><th>Security</th><th>GICS Sector</th></tr>\n",
    "      <tr><td>AAA</td><td>Demo Corp</td><td>Industrials</td></tr>\n",
    "      <tr><td>BBB</td><td>Example Inc</td><td>Technology</td></tr>\n",
    "    </table>\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    rows = []\n",
    "    for tr in soup.find_all(\"tr\"):\n",
    "        cells = [td.get_text(strip=True) for td in tr.find_all(['td','th'])]\n",
    "        if cells:\n",
    "            rows.append(cells)\n",
    "    header, *data = rows\n",
    "    df_scrape = pd.DataFrame(data, columns=header)\n",
    "\n",
    "# --- Validation ---\n",
    "df_scrape.columns = df_scrape.columns.str.strip().str.replace(\"\\n\", \" \", regex=True)\n",
    "required_cols = [\"Symbol\", \"Security\"]\n",
    "missing = [c for c in required_cols if c not in df_scrape.columns]\n",
    "assert not missing, f\"Missing required columns: {missing}\"\n",
    "\n",
    "gics_cols = [c for c in df_scrape.columns if \"GICS\" in c]\n",
    "assert gics_cols, \"No GICS-related columns found\"\n",
    "\n",
    "assert df_scrape[\"Symbol\"].notna().all(), \"Symbol column has NA values\"\n",
    "assert df_scrape[\"Security\"].notna().all(), \"Security column has NA values\"\n",
    "for col in gics_cols:\n",
    "    assert df_scrape[col].notna().all(), f\"{col} has NA values\"\n",
    "\n",
    "assert len(df_scrape) > 400, \"Row count too small, scraping likely failed\"\n",
    "\n",
    "print(\"Validation passed (Scraping)\")\n",
    "\n",
    "# --- Save ---\n",
    "fname2 = f\"scrape_wikipedia_sp500_{pd.Timestamp.now().strftime('%Y%m%d-%H%M')}.csv\"\n",
    "out_path2 = (Path(\"..\") / \"data\" / \"raw\" / fname2)\n",
    "df_scrape.to_csv(out_path2, index=False)\n",
    "print(\"Saved:\", out_path2)\n",
    "\n",
    "df_scrape.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac657f1",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "\n",
    "**Data Sources**  \n",
    "- Alpha Vantage API: `https://www.alphavantage.co/query` (used to download stock time series data)  \n",
    "- Yahoo Finance Markets Table: `https://finance.yahoo.com/markets` (public webpage with simple market data table)  \n",
    "\n",
    "**Parameters**  \n",
    "- Symbol: AAPL  \n",
    "- Function: TIME_SERIES_DAILY_ADJUSTED  \n",
    "- Outputsize: compact  \n",
    "- API Key: stored securely in `.env`  \n",
    "\n",
    "**Validation Logic**  \n",
    "- Checked required columns (`date`, `adj_close`) are present  \n",
    "- Verified no missing values in critical columns  \n",
    "- Ensured DataFrame is non-empty  \n",
    "- For scraped table: validated numeric/text columns have correct types  \n",
    "\n",
    "**Assumptions & Risks**  \n",
    "- API data may be delayed or limited by rate limits  \n",
    "- Scraped webpage structure may change without notice  \n",
    "- Network errors could interrupt data acquisition\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bootcamp_env)",
   "language": "python",
   "name": "bootcamp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
